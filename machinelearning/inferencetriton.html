<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Triton Inference Server | HTDP1</title>
    <meta name="generator" content="VuePress 1.8.2">
    
    <meta name="description" content="htdp1 github pages">
    <meta name="theme-color" content="#3eaf7c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    
    <link rel="preload" href="/am-arch/assets/css/0.styles.cf1d3b34.css" as="style"><link rel="preload" href="/am-arch/assets/js/app.89e1056e.js" as="script"><link rel="preload" href="/am-arch/assets/js/2.158b03bb.js" as="script"><link rel="preload" href="/am-arch/assets/js/19.d66be9cb.js" as="script"><link rel="prefetch" href="/am-arch/assets/js/10.f985dceb.js"><link rel="prefetch" href="/am-arch/assets/js/11.13a0885b.js"><link rel="prefetch" href="/am-arch/assets/js/12.784f5764.js"><link rel="prefetch" href="/am-arch/assets/js/13.0705463a.js"><link rel="prefetch" href="/am-arch/assets/js/14.edf1e9bf.js"><link rel="prefetch" href="/am-arch/assets/js/15.ecbe92b4.js"><link rel="prefetch" href="/am-arch/assets/js/16.b0e5273b.js"><link rel="prefetch" href="/am-arch/assets/js/17.c1412e8f.js"><link rel="prefetch" href="/am-arch/assets/js/18.2bf38a43.js"><link rel="prefetch" href="/am-arch/assets/js/20.2d12a517.js"><link rel="prefetch" href="/am-arch/assets/js/21.4a5538a4.js"><link rel="prefetch" href="/am-arch/assets/js/22.b2655bc9.js"><link rel="prefetch" href="/am-arch/assets/js/23.f69f4766.js"><link rel="prefetch" href="/am-arch/assets/js/24.d9cb860d.js"><link rel="prefetch" href="/am-arch/assets/js/25.7a3200a9.js"><link rel="prefetch" href="/am-arch/assets/js/26.5cb3a254.js"><link rel="prefetch" href="/am-arch/assets/js/27.0c63f9e7.js"><link rel="prefetch" href="/am-arch/assets/js/28.58281d66.js"><link rel="prefetch" href="/am-arch/assets/js/29.164199d9.js"><link rel="prefetch" href="/am-arch/assets/js/3.0b98036c.js"><link rel="prefetch" href="/am-arch/assets/js/30.495713a6.js"><link rel="prefetch" href="/am-arch/assets/js/31.4507fc8d.js"><link rel="prefetch" href="/am-arch/assets/js/32.e2d5f511.js"><link rel="prefetch" href="/am-arch/assets/js/33.5a7d28a0.js"><link rel="prefetch" href="/am-arch/assets/js/34.24927452.js"><link rel="prefetch" href="/am-arch/assets/js/35.b946ec72.js"><link rel="prefetch" href="/am-arch/assets/js/36.3e0df84b.js"><link rel="prefetch" href="/am-arch/assets/js/37.baf5ac72.js"><link rel="prefetch" href="/am-arch/assets/js/38.924d0d58.js"><link rel="prefetch" href="/am-arch/assets/js/39.c9ada2db.js"><link rel="prefetch" href="/am-arch/assets/js/4.3bf6929e.js"><link rel="prefetch" href="/am-arch/assets/js/40.59ff4950.js"><link rel="prefetch" href="/am-arch/assets/js/41.e36e5e29.js"><link rel="prefetch" href="/am-arch/assets/js/42.8fbd702b.js"><link rel="prefetch" href="/am-arch/assets/js/43.682ed0be.js"><link rel="prefetch" href="/am-arch/assets/js/44.e96bd250.js"><link rel="prefetch" href="/am-arch/assets/js/45.e5548ca0.js"><link rel="prefetch" href="/am-arch/assets/js/46.eb3135d2.js"><link rel="prefetch" href="/am-arch/assets/js/47.75bfb6d8.js"><link rel="prefetch" href="/am-arch/assets/js/48.24475551.js"><link rel="prefetch" href="/am-arch/assets/js/49.4f9d97da.js"><link rel="prefetch" href="/am-arch/assets/js/5.612537aa.js"><link rel="prefetch" href="/am-arch/assets/js/50.9396ae6a.js"><link rel="prefetch" href="/am-arch/assets/js/51.0246b6e3.js"><link rel="prefetch" href="/am-arch/assets/js/52.b63d5ce3.js"><link rel="prefetch" href="/am-arch/assets/js/53.1f0c3f8c.js"><link rel="prefetch" href="/am-arch/assets/js/54.945e81a6.js"><link rel="prefetch" href="/am-arch/assets/js/55.7f8cfc43.js"><link rel="prefetch" href="/am-arch/assets/js/56.c5892f1b.js"><link rel="prefetch" href="/am-arch/assets/js/57.95dda11c.js"><link rel="prefetch" href="/am-arch/assets/js/58.5239fcca.js"><link rel="prefetch" href="/am-arch/assets/js/59.8c2edf4b.js"><link rel="prefetch" href="/am-arch/assets/js/6.744bf98a.js"><link rel="prefetch" href="/am-arch/assets/js/60.41a76796.js"><link rel="prefetch" href="/am-arch/assets/js/61.26101a83.js"><link rel="prefetch" href="/am-arch/assets/js/62.f17e7ccd.js"><link rel="prefetch" href="/am-arch/assets/js/63.26013c6d.js"><link rel="prefetch" href="/am-arch/assets/js/64.5a311c5f.js"><link rel="prefetch" href="/am-arch/assets/js/65.eb28022b.js"><link rel="prefetch" href="/am-arch/assets/js/7.fed2825e.js"><link rel="prefetch" href="/am-arch/assets/js/8.8c182984.js"><link rel="prefetch" href="/am-arch/assets/js/9.3fd7e149.js">
    <link rel="stylesheet" href="/am-arch/assets/css/0.styles.cf1d3b34.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="global-layout"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/am-arch/" class="home-link router-link-active"><!----> <span class="site-name">HTDP1</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/am-arch/guide/" class="nav-link">
  Guide
</a></div><div class="nav-item"><a href="/am-arch/cloud/" class="nav-link">
  Cloud
</a></div><div class="nav-item"><a href="/am-arch/refarch/" class="nav-link">
  Ref. Arch.
</a></div><div class="nav-item"><a href="/am-arch/cloud-native-app/" class="nav-link">
  Cloud.Native.App
</a></div><div class="nav-item"><a href="/am-arch/machinelearning/" class="nav-link router-link-active">
  M / L
</a></div><div class="nav-item"><a href="/am-arch/gitops/" class="nav-link">
  GitOps
</a></div><div class="nav-item"><a href="/am-arch/multi-cloud/" class="nav-link">
  Multi Cloud
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/am-arch/guide/" class="nav-link">
  Guide
</a></div><div class="nav-item"><a href="/am-arch/cloud/" class="nav-link">
  Cloud
</a></div><div class="nav-item"><a href="/am-arch/refarch/" class="nav-link">
  Ref. Arch.
</a></div><div class="nav-item"><a href="/am-arch/cloud-native-app/" class="nav-link">
  Cloud.Native.App
</a></div><div class="nav-item"><a href="/am-arch/machinelearning/" class="nav-link router-link-active">
  M / L
</a></div><div class="nav-item"><a href="/am-arch/gitops/" class="nav-link">
  GitOps
</a></div><div class="nav-item"><a href="/am-arch/multi-cloud/" class="nav-link">
  Multi Cloud
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Introduction</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/am-arch/machinelearning/" aria-current="page" class="sidebar-link">Overview</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading"><span>Jupyter</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/am-arch/machinelearning/jupyterintro.html" class="sidebar-link">Basics</a></li><li><a href="/am-arch/machinelearning/jupyterserver.html" class="sidebar-link">Jupyter Server</a></li><li><a href="/am-arch/machinelearning/jupyterhub.html" class="sidebar-link">Jupyter Hub</a></li><li><a href="/am-arch/machinelearning/jupyterproxy.html" class="sidebar-link">Jupyter Server Proxy</a></li></ul></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Inference</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/am-arch/machinelearning/inferenceintro.html" class="sidebar-link">Inroduction</a></li><li><a href="/am-arch/machinelearning/inferencetriton.html" aria-current="page" class="active sidebar-link">Triton Inference Server</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/am-arch/machinelearning/inferencetriton.html#introduction" class="sidebar-link">Introduction</a></li><li class="sidebar-sub-header"><a href="/am-arch/machinelearning/inferencetriton.html#architecture" class="sidebar-link">Architecture</a></li><li class="sidebar-sub-header"><a href="/am-arch/machinelearning/inferencetriton.html#kubernetes-deploy" class="sidebar-link">Kubernetes Deploy</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/am-arch/machinelearning/inferencetriton.html#tritonserver-helm-chart-배포" class="sidebar-link">tritonserver helm chart 배포</a></li><li class="sidebar-sub-header"><a href="/am-arch/machinelearning/inferencetriton.html#inference-request-monitoring" class="sidebar-link">Inference Request Monitoring</a></li><li class="sidebar-sub-header"><a href="/am-arch/machinelearning/inferencetriton.html#sdk-client-test" class="sidebar-link">SDK Client Test</a></li></ul></li></ul></li><li><a href="/am-arch/machinelearning/inferencekfserving.html" class="sidebar-link">KFServing</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="triton-inference-server"><a href="#triton-inference-server" class="header-anchor">#</a> Triton Inference Server</h1> <h2 id="introduction"><a href="#introduction" class="header-anchor">#</a> Introduction</h2> <p>Triton Inference Server는 CPU와 GPU 모두에 최적화된 Cloud / Edge Inference Solution 을 제공한다. Triton은 HTTP/REST 및 GRPC 프로토콜을 지원하여 원격 클라이언트가 서버에서 관리하는 모든 모델에 대한 Inferencing 을 요청할 수 있도록 한다</p> <ul><li>Features
<ul><li>Multiple deep-learning framework 지원</li> <li>Concurrent Model Execution</li> <li>Dynamic Batching</li> <li><em><b><u>KFServing Protocol</u></b></em></li></ul></li></ul> <p>위와 같은 다양한 기능이 제공되며,<br>
Triton 기능 점검이 아닌, Kubernetes 환경에서의 Triton Inference Server 구성 및 테스트를 진행함.<br>
Model Serving 관련 KFServing 구성 및 InferenceService 테스트를 진행함.</p> <h2 id="architecture"><a href="#architecture" class="header-anchor">#</a> Architecture</h2> <p>Kubernetes 환경에서는 deployment 를 통한 pod 으로 단순하게 구성되지만, 내부적으로는 아래와 같은 구조를 갖고 있다.</p> <ul><li><p>Model Repository</p> <ul><li>Triton Inferencing 에 사용할 수 있는 파일 시스템 기반의 저장소이며, Volume Mount 및 Object Storage 활용 가능.</li> <li>Triton Server 실행 시, --model-store option 으로 directory 를 지정.</li></ul></li> <li><p>Client Request Scheduling / Routing</p> <ul><li>Inferencing 요청은 HTTP/REST, GRPC 호출 혹은, C API 직접 호출을 통하여 가능.</li> <li>내부적으로 Model 별 Scheduler 로 Routing.</li> <li>Model Repository 에서 load 한 model 각각의 스케줄링 및 처리 알고리즘이 구현됨.</li></ul></li> <li><p>Framework Backends</p> <ul><li>Inferencing 요청 Model 유형에 해당하는 Framework Backend 로 전달됨.</li> <li>Inference 수행 및 Output Return.</li></ul></li> <li><p>Monitoring</p> <ul><li>Kubernetes 에 통합 가능한 Readiness, Liveness, 처리량 및 대기 시간 등의 metric 활용 가능</li></ul></li> <li><p>Triton High-Level Architecture<br> <img src="https://github.com/triton-inference-server/server/raw/main/docs/images/arch.jpg" title="triton-arch" alt="triton-arch"></p></li></ul> <blockquote><p>Triton Inference Server Github Repository<br> <a href="https://github.com/triton-inference-server/server" target="_blank" rel="noopener noreferrer">https://github.com/triton-inference-server/server<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br>
Triton Inference Server Architecture 참조<br> <a href="https://github.com/triton-inference-server/server/blob/main/docs/architecture.md" target="_blank" rel="noopener noreferrer">https://github.com/triton-inference-server/server/blob/main/docs/architecture.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <h2 id="kubernetes-deploy"><a href="#kubernetes-deploy" class="header-anchor">#</a> Kubernetes Deploy</h2> <p>AWS EKS 환경에 deploy 하기 위한 Helm Chart 를 제공. 공식 가이드는 tiller 구성을 포함하고 있으나, 해당 구성 없이 helm v3 활용하여 설치하였음.<br>
기본적으로 deployment 로 pod 이 생성되며, replicas 관리를 통해서 HA 구성을 하도록 가이드하고 있음.</p> <ul><li>작업 순서
<ol><li>Amazon EKS Cluster 생성</li> <li>Amazon S3 Model Repository 구성</li> <li>triton-inference-server helm chart 배포</li> <li>Monitoring 을 위한 prometheus-operator helm chart 배포</li> <li>triton-inference-server sdk client 구성 및 inferencing 테스트</li></ol></li></ul> <blockquote><p>Triton Inference Server AWS Deploy Guide<br> <a href="https://github.com/htdp1/mlops-k8s/tree/main/triton-inference-server/deploy/aws" target="_blank" rel="noopener noreferrer">https://github.com/htdp1/mlops-k8s/tree/main/triton-inference-server/deploy/aws<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a><br>
Triton Quick Start Guide<br> <a href="https://github.com/triton-inference-server/server/blob/main/docs/quickstart.md" target="_blank" rel="noopener noreferrer">https://github.com/triton-inference-server/server/blob/main/docs/quickstart.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <h3 id="tritonserver-helm-chart-배포"><a href="#tritonserver-helm-chart-배포" class="header-anchor">#</a> tritonserver helm chart 배포</h3> <ul><li>S3 에 Access 하기 위한 AWS Access Key 를 values.yaml 에 mapping</li> <li>imageName, modelRepositoryPath, cpu 등 수정</li> <li>LoadBalancer 로 Service 생성하여, Amazon Classic Load Balancer 생성</li></ul> <div class="language-yaml line-numbers-mode"><pre class="language-yaml"><code><span class="token key atrule">replicaCount</span><span class="token punctuation">:</span> <span class="token number">1</span>

<span class="token key atrule">service</span><span class="token punctuation">:</span>
  <span class="token key atrule">type</span><span class="token punctuation">:</span> LoadBalancer

<span class="token key atrule">image</span><span class="token punctuation">:</span>
  <span class="token key atrule">imageName</span><span class="token punctuation">:</span> nvcr.io/nvidia/tritonserver<span class="token punctuation">:</span>21.04<span class="token punctuation">-</span>py3
  <span class="token key atrule">pullPolicy</span><span class="token punctuation">:</span> IfNotPresent
  <span class="token key atrule">modelRepositoryPath</span><span class="token punctuation">:</span> s3<span class="token punctuation">:</span>//htdp1<span class="token punctuation">-</span>triton<span class="token punctuation">-</span>inference<span class="token punctuation">-</span>server<span class="token punctuation">-</span>repository/model_repository
  <span class="token comment"># numGpus: 1</span>
  <span class="token key atrule">numCpus</span><span class="token punctuation">:</span> <span class="token number">1</span>

<span class="token key atrule">secret</span><span class="token punctuation">:</span> 
  <span class="token punctuation">...</span>

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><ul><li>result</li></ul> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code>$ kubectl get all -n triton
NAME                                                 READY   STATUS    RESTARTS   AGE
pod/htdp1-triton-inference-server-6b969d654c-n6xkn   <span class="token number">1</span>/1     Running   <span class="token number">0</span>          39m

NAME                                            TYPE           CLUSTER-IP       EXTERNAL-IP    PORT<span class="token punctuation">(</span>S<span class="token punctuation">)</span>                                         AGE
service/htdp1-triton-inference-server           LoadBalancer   <span class="token number">10.100</span>.209.89    <span class="token operator">&lt;</span>External-IP<span class="token operator">&gt;</span>   <span class="token number">8000</span>:31422/TCP,8001:31024/TCP,8002:30129/TCP   3h24m
service/htdp1-triton-inference-server-metrics   ClusterIP      <span class="token number">10.100</span>.179.240   <span class="token operator">&lt;</span>none<span class="token operator">&gt;</span>          <span class="token number">8080</span>/TCP   3h24m

NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/htdp1-triton-inference-server   <span class="token number">1</span>/1     <span class="token number">1</span>            <span class="token number">1</span>           3h24m

NAME                                                       DESIRED   CURRENT   READY   AGE
replicaset.apps/htdp1-triton-inference-server-6b969d654c   <span class="token number">1</span>         <span class="token number">1</span>         <span class="token number">1</span>       3h24m
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><ul><li>logs</li></ul> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code>
<span class="token comment"># Framework Backend</span>
I0526 03:39:25.498911 <span class="token number">1</span> server.cc:543<span class="token punctuation">]</span>
+-------------+-----------------------------------------------------------------+--------+
<span class="token operator">|</span> Backend     <span class="token operator">|</span> Path                                                            <span class="token operator">|</span> Config <span class="token operator">|</span>
+-------------+-----------------------------------------------------------------+--------+
<span class="token operator">|</span> tensorrt    <span class="token operator">|</span> <span class="token operator">&lt;</span>built-in<span class="token operator">&gt;</span>                                                      <span class="token operator">|</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>     <span class="token operator">|</span>
<span class="token operator">|</span> pytorch     <span class="token operator">|</span> /opt/tritonserver/backends/pytorch/libtriton_pytorch.so         <span class="token operator">|</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>     <span class="token operator">|</span>
<span class="token operator">|</span> tensorflow  <span class="token operator">|</span> /opt/tritonserver/backends/tensorflow1/libtriton_tensorflow1.so <span class="token operator">|</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>     <span class="token operator">|</span>
<span class="token operator">|</span> onnxruntime <span class="token operator">|</span> /opt/tritonserver/backends/onnxruntime/libtriton_onnxruntime.so <span class="token operator">|</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>     <span class="token operator">|</span>
<span class="token operator">|</span> openvino    <span class="token operator">|</span> /opt/tritonserver/backends/openvino/libtriton_openvino.so       <span class="token operator">|</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>     <span class="token operator">|</span>
+-------------+-----------------------------------------------------------------+--------+

<span class="token comment"># Model Repository 에 있는 Model Loading</span>
I0526 03:39:25.498991 <span class="token number">1</span> server.cc:586<span class="token punctuation">]</span>
+----------------------+---------+--------+
<span class="token operator">|</span> Model                <span class="token operator">|</span> Version <span class="token operator">|</span> Status <span class="token operator">|</span>
+----------------------+---------+--------+
<span class="token operator">|</span> densenet_onnx        <span class="token operator">|</span> <span class="token number">1</span>       <span class="token operator">|</span> READY  <span class="token operator">|</span>
<span class="token operator">|</span> inception_graphdef   <span class="token operator">|</span> <span class="token number">1</span>       <span class="token operator">|</span> READY  <span class="token operator">|</span>
<span class="token operator">|</span> simple               <span class="token operator">|</span> <span class="token number">1</span>       <span class="token operator">|</span> READY  <span class="token operator">|</span>
<span class="token operator">|</span> simple_dyna_sequence <span class="token operator">|</span> <span class="token number">1</span>       <span class="token operator">|</span> READY  <span class="token operator">|</span>
<span class="token operator">|</span> simple_identity      <span class="token operator">|</span> <span class="token number">1</span>       <span class="token operator">|</span> READY  <span class="token operator">|</span>
<span class="token operator">|</span> simple_int8          <span class="token operator">|</span> <span class="token number">1</span>       <span class="token operator">|</span> READY  <span class="token operator">|</span>
<span class="token operator">|</span> simple_sequence      <span class="token operator">|</span> <span class="token number">1</span>       <span class="token operator">|</span> READY  <span class="token operator">|</span>
<span class="token operator">|</span> simple_string        <span class="token operator">|</span> <span class="token number">1</span>       <span class="token operator">|</span> READY  <span class="token operator">|</span>
+----------------------+---------+--------+

<span class="token punctuation">..</span>.

<span class="token comment"># 기본 Service Port (HTTP, GRPC, Metric)</span>
I0526 03:39:25.500218 <span class="token number">1</span> grpc_server.cc:4028<span class="token punctuation">]</span> Started GRPCInferenceService at <span class="token number">0.0</span>.0.0:8001
I0526 03:39:25.500467 <span class="token number">1</span> http_server.cc:2761<span class="token punctuation">]</span> Started HTTPService at <span class="token number">0.0</span>.0.0:8000
I0526 03:39:25.541702 <span class="token number">1</span> http_server.cc:2780<span class="token punctuation">]</span> Started Metrics Service at <span class="token number">0.0</span>.0.0:8002

<span class="token punctuation">..</span>.

</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br></div></div><h3 id="inference-request-monitoring"><a href="#inference-request-monitoring" class="header-anchor">#</a> Inference Request Monitoring</h3> <p>stable/prometheus 를 배포하여, inference request Monitoring.<br>
배포 시, <em>prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false</em> 지정해야, prometheus 가 inferece server metric 을 추적할 수 있다.</p> <ul><li>triton server 에서 제공하는 Grafana Dashboard
<ul><li>Inference Request 에 대한 처리 metric 이 모델마다 각각 추적됨. (repository model 8개)</li> <li>Scheduling 을 위한 Queue 도 각각 생성됨.</li></ul></li></ul> <p><img src="/am-arch/assets/img/triton-grafana-dashboard.dee5800d.png" alt=""></p> <blockquote><p>grafana dashboard.json 참조<br> <a href="https://github.com/triton-inference-server/server/blob/main/deploy/aws/dashboard.json" target="_blank" rel="noopener noreferrer">https://github.com/triton-inference-server/server/blob/main/deploy/aws/dashboard.json<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <h3 id="sdk-client-test"><a href="#sdk-client-test" class="header-anchor">#</a> SDK Client Test</h3> <p>Triton Inference Server 에 경우, 특정한 directory 구조 및 file 을 갖고 있어야 model 을 실행할 수 있다. sample 로 제공되는 model 을 활용하여, Amazon S3 에 Model Repository 를 구성하고, EKS 에 배포된 triton-inference-server 에 sample model inference 요청 테스트를 한 결과이다.</p> <blockquote><p>triton sample model 참조<br> <a href="https://github.com/triton-inference-server/server/tree/main/docs/examples/model_repository" target="_blank" rel="noopener noreferrer">https://github.com/triton-inference-server/server/tree/main/docs/examples/model_repository<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></blockquote> <ul><li>triton-inference-server SDK Docker container 실행</li></ul> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code>docker pull nvcr.io/nvidia/tritonserver:21.04-py3-sdk
docker run -it --rm --net<span class="token operator">=</span>host nvcr.io/nvidia/tritonserver:21.04-py3-sdk
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><ul><li>SDK container 에 접속하여, image_client 를 실행하여 http request test 한 결과</li></ul> <div class="language-sh line-numbers-mode"><pre class="language-sh"><code><span class="token comment"># densenet_onnx 실행</span>
root@docker-desktop:/workspace<span class="token comment"># /workspace/install/bin/image_client -m densenet_onnx -c 3 -s INCEPTION -u &lt;External-IP&gt;:8000 /workspace/images/mug.jpg</span>
Request <span class="token number">0</span>, batch size <span class="token number">1</span>
Image <span class="token string">'/workspace/images/mug.jpg'</span><span class="token builtin class-name">:</span>
    <span class="token number">15.349564</span> <span class="token punctuation">(</span><span class="token number">504</span><span class="token punctuation">)</span> <span class="token operator">=</span> COFFEE MUG
    <span class="token number">13.227464</span> <span class="token punctuation">(</span><span class="token number">968</span><span class="token punctuation">)</span> <span class="token operator">=</span> CUP
    <span class="token number">10.424892</span> <span class="token punctuation">(</span><span class="token number">505</span><span class="token punctuation">)</span> <span class="token operator">=</span> COFFEEPOT

<span class="token comment"># inception_graphdef 실행</span>
root@docker-desktop:/workspace<span class="token comment"># /workspace/install/bin/image_client -m inception_graphdef -c 3 -s INCEPTION -u &lt;External-IP&gt;:8000 /workspace/images/mug.jpg</span>
Request <span class="token number">0</span>, batch size <span class="token number">1</span>
Image <span class="token string">'/workspace/images/mug.jpg'</span><span class="token builtin class-name">:</span>
    <span class="token number">0.754047</span> <span class="token punctuation">(</span><span class="token number">505</span><span class="token punctuation">)</span> <span class="token operator">=</span> COFFEE MUG
    <span class="token number">0.157066</span> <span class="token punctuation">(</span><span class="token number">969</span><span class="token punctuation">)</span> <span class="token operator">=</span> CUP
    <span class="token number">0.002878</span> <span class="token punctuation">(</span><span class="token number">968</span><span class="token punctuation">)</span> <span class="token operator">=</span> ESPRESSO
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br></div></div><ul><li>각 model 이 처리된 내역 Monitoring</li></ul> <p><img src="/am-arch/assets/img/triton-inference-testresult.b934554e.png" alt=""></p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/am-arch/machinelearning/inferenceintro.html" class="prev">
        Inroduction
      </a></span> <span class="next"><a href="/am-arch/machinelearning/inferencekfserving.html">
        KFServing
      </a>
      →
    </span></p></div> </main></div></div><div class="global-ui"></div></div>
    <script src="/am-arch/assets/js/app.89e1056e.js" defer></script><script src="/am-arch/assets/js/2.158b03bb.js" defer></script><script src="/am-arch/assets/js/19.d66be9cb.js" defer></script>
  </body>
</html>
